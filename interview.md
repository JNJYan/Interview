[TOC]
# C++
## new
### operator new
可以进行重载的运算符，通过重载定制内存分配，重载返回类型未void*，第一个参数类型为分配空间的大小，类型为size_t

### new operator
new关键字，调用operatornew和构造函数。

### placement new
## C++11特性
### 右值引用
先介绍一下左值右值，左值是指能够获取到地址的值，能否用取地址运算符获得对象的内存地址，对于临时对象，存储与寄存器中，是没有办法调用
右值引用的作用是来实现移动语义和完美转发

#### 移动语义
解决对象的资源所有权转移问题，

### lambda
```c++
int a, b;
auto f = [=, &b](int n){b++; return n+a;}
```
## 概念
### C/C++
1. 面向过程是分析出解决问题的关键，然后将这些步骤逐步实现，按顺序调用就可以了。

2. 面向对象，把问题分解成各个对象，不是为了完成一个过程，而是为了描述某个事物在整个问题解决过程中的行为。

### OOP
三大特性：封装、继承、多态。
1. 封装：将内部的实现细节和数据成员隐藏起来，外部对象只通过留好的接口进行访问和调用，保证了内部数据地安全性，也隐藏了复杂的实现细节，当内部实现发生变化时，对外部影响较小。C++类的成员函数和数据成员的访问类型有三种，public、private、protected。
2. 继承：如果子类属于父类的一种，拥有父类的所有属性和方法，就不需要编写相同的代码，实现复用。
3. 多态：可以用相同的方式根据不同的对象执行不同的操作，C++里允许将父类的指针和引用指向一个子类对象，从而根据具体的对象类型，来调用不同的方法，是通过虚函数实现的。如果某一个方法要被子类所重写，就要将该方法声明为虚方法。

4. 多态：多态的本质是可以由一个指针或引用根据其实际指向对象的不同表现出不同的行为，与此有类似行为的有函数指针，将函数赋值给函数指针，从而可以通过调用指针的方式来实现不同的行为。

### 静态链接/动态链接
1. 静态链接：由链接器将库的内容加入到可执行程序中，将要调用的函数链接到可执行文件中，成为可执行文件的一部分。
2. 动态链接：没有加入到可执行文件中，而是加入了调用函数的描述信息(重定位)，程序运行时采取建立链接关系，`.dll`。

### 静态库/动态库
1. 静态库：windows下`.lib`，linux下`.a`
2. 动态库：windows下`.dll`，linux下`.so`

### 静态编译/动态编译
静态编译：提取库中需要的部分，链接到可执行文件中，会被重复装载，浪费内存，如果有静态库需要更新，则程序需要重新编译。
动态编译：依赖于外部动态库，在运行时去调用，库更新时，不需要重新编译。

### 堆栈溢出
1. 栈溢出
递归调用次数过多导致的，通过尾递归来解决。

2. 堆溢出
缓冲区溢出，写操作超出缓冲区范围，覆盖了已有数据。

### 全局变量/局部变量
在局部变量的作用域范围内，局部变量会屏蔽对全局变量的访问。

可以通过`::`作用域限定符来访问全局变量。

### 内存泄漏
内存分配分两种，一种是在栈上分配，像局部变量、形参、函数调用返回地址等，这部分有操作系统来执行分配和释放，不会发生什么错误。
还有一种，程序员自己使用malloc或者new来从堆上申请内存，在使用之后，却忘记释放该内存，随着程序运行时间越来越长，泄漏的内存越多，最终用尽了所有内存，导致整个系统崩溃。

1. 调用new或malloc为对象分配了内存，却没有显式地释放这个对象所占用的内存。
2. 在类的构造函数或成员函数里动态分配了内存，而在析构函数里却没有释放。
3. 该delete[]时只调用了delete，因此只是放了一个对象。
4. 没有将基类的析构函数定义为虚函数。

### 野指针
1. 在类里面有指针成员变量，却没有显式编写拷贝构造函数和重载赋值运算符，导致浅拷贝。
2. 指针变量没有初始化。
3. 指针被释放之后，没有设置为nullptr。
4. 指针操作超越了变量的作用范围。

### 函数调用
在函数调用的时候，有这么几个概念，一个是栈帧的概念，对于每一个函数都有创建一个栈帧，在栈帧里面有两个指针，一个指向栈底，一个指向栈顶。

函数调用的过程，首先将返回地址压入栈中，返回地址就就是我们调用函数的下一个语句，然后将调用函数的参数自右向左压入栈中，然后创建调用函数的栈帧，调用函数栈帧底部应当存放当前函数的栈底指针指向的地址。

自右向左的原因是为了实现变长参数，最左侧的参数位于栈顶，如果是自左向右的话，因为不确定参数的个数，也就无法获取到第一个参数。

这里的实现可以是先压返回地址，再压参数，也可以先压参数，再压入返回地址。

先压返回地址再压参数是为了更容易实现尾递归：
由于尾递归不再需要保留当前函数的调用栈，因此先压返回地址再压参数，可以直接将当前函数参数弹出，再继续压入尾递归函数的参数。递归深度可以无限增加，因为只有一个函数栈帧。而先压入参数，再压返回地址的话，为了实现尾递归，需要额外保存返回地址，将参数弹出，然后将新函数的参入压入，再压入旧的返回地址。


### 虚函数
c++中多态是通过虚函数的方式来实现的，虚函数的实现原理是，对于每一个类都会有一个虚函数表，(只有在有虚函数的时候，才会有虚函数表)，类的实例化对象都会有一个虚函数表指针指向该类的虚函数表。编译时虚函数表就确定了，所以虚函数表存放在只读数据段上。

多继承中，派生类对象会有多个虚函数表指针指向多个虚函数表。

#### 纯虚函数
通过将一个虚函数声明为等于0的方式，声明一个纯虚函数从而将类变为一个抽象类。该类的虚函数表上该函数的地址被赋值为0，而编译器绝不允许一个函数指向一个0地址，因此拒绝为抽象类进行实例化。

### 字节对齐
结构体/类内部，按照下一个元素的类型大小的整数倍进行对齐，前面元素不足的补齐，整个结构体/类的大小按照结构体/类中最大的类型进行地址对齐。

### 虚析构函数
当父类析构函数声明为虚函数时，父类的虚函数表中会添加一个指向父类析构函数的函数指针，派生类没有显式定义一个析构函数时，编译器会生成一个默认的虚析构函数，并用添加一个指向子类析构函数的函数指针到虚函数表中(不是覆盖到父类的虚析构)，这样我们调用delete时，就可以通过虚函数表指针获取到派生类的析构函数。

### 虚构造函数
构造函数不能为虚函数。

1. 虚函数的实现是通过虚函数表和对象中的虚函数表指针来实现的，调用构造函数时，对象还没有创建完成，也就没有虚函数表指针，因此不能。
2. 虚函数本身就是为了一个基类指针或者引用指向一个派生类对象时使用的，


## 对比
### sizeof/strlen
`sizeof`：运算符，编译时已经计算好了，返回的是字符数组在内存中占用的空间，包含末尾空字符`\0`，当给定函数时，返回函数返回类型占用空间的大小，给定指针时，返回指针的大小。
`strlen`：库函数，返回的是字符串的长度即有效字符的个数，从给定地址遍历直到遇到`\0`。

### new/malloc
1. `new`是一个关键字，只需要编译器支持，而`malloc`是一个库函数，需要引入头文件。
2. `new`从自由存储区分配空间，而`malloc`只能从堆上分配空间。
3. `new`分配空间只需要指定类型和个数，而`malloc`需要指定具体分配的空间大小。
4. `new`直接返回指定类型的指针，而`malloc`返回`void *`指针，需要进行强制转换。
5. `new`分配失败返回`bad_alloc`异常，而`malloc`返回空指针。
6. `new`分配对象内存时，三个过程，第一步调用`operator new`分配空间，第二步调用类型的构造函数在分配的空间上创建对象，第三步，将指针指向该对象。
7. `new`分配的要调用`delete`释放，会执行析构函数，而`malloc`通过`free`释放。
8. `new`和`delete`可以被重载，而`malloc/free`虽然是函数但不能被重载。

### strcpy/memcpy
1. strcpy只能用来复制字符串，而memcpy可以复制任何内容。
2. 复制的方法不同，strcpy不需要指定长度，复制到`\0`结束，若空间不足，产生溢出。而memcpy则指定复制的长度。
3. 对于包含`\0`的字符串，只能用memcpy


### 指针/引用
1. 指针是一个拥有实际内存空间的一个对象，相当于一个变量，存储的是一个地址，而引用只是变量的一个别名。
2. 引用在声明的时候必须完成初始化，不能为空，而指针可以先声明，再为其初始化，指针也可以为空。
3. 引用是不能更改的，而指针则可以指向不同的对象。
4. sizeof(引用)得到的是对象的大小，而sizeof(指针)是指针本身的大小。
5. 引用本身就是就是该对象，而指针本身的内容是对象的地址，需要对其解引用才能获取对象。
6. 自增，引用自增等同于变量自增，指针自增，相当于指向的地址发生变化。
7. 作为形参时，指针我们需要实现判断是否为空，而引用不需要。
8. 传引用要比传指针安全，引用不能为空，且对象不能改变。而指针不仅指向的对象可变，而且可以为空，甚至是一个野指针。

### 数组指针遍历/下标遍历
```c++
a[20] = (a[0] + 20*4);
*p++ = (p+4)
```
下标遍历，每次都是从数组起始地址开始算，有乘法操作。


## 强制类型转换
### const_cast
### static_cast
### dynamic_cast
只能用于转换有继承关系的两个类，且必须被转换对象必须拥有虚方法(自己得或继承于基类的)。

没有虚方法则编译期间报错。

从基类指针到派生类指针的转换，在运行时进行检查，若不是继承关系，则指针转换返回空指针。

上述情况包含两种，一种是基类指针指向派生类向派生类指针转换，没有安全问题。另一种是基类指针指向基类向派生类指针进行转换，如上。

派生类到基类的转换没有安全问题。
### reinterpert_cast

## 关键字

### inline
引入内联函数的主要目的是，代替C语言中宏定义方式来解决函数调用的效率问题。

由于是为了解决频繁调用函数的效率问题，因此内联函数通常应该在循环语句内部，如果该函数只执行有限几次，也就没必要使用内联。

宏定义的问题在于，宏替换是在编译过程中第一步预处理阶段完成的，c++编译器无法对宏定义函数进行类型检查，返回值也无法进行强制的类型转换，而内联函数是在编译时展开。

`inline`只是建议编译器进行内联优化，不能包含复杂的结构控制语句，如循环、switch，不能递归。而且`inline`放在函数声明前是无效的，必须要跟函数定义在一起。

inline的范围只在源文件内部，即不能被其他文件所使用。

在定义类内部定义的函数，默认是inline的。

inline函数的经典应用是类里面的读取/写入成员变量。

缺点在于，每次调用时，都复制了一份代码，因此会导致二进制文件增大。

### static
1. 修饰全局变量和全局函数，作用为当前文件
2. 修饰局部变量，持久化
3. 修饰成员变量和成员函数，属于类而非对象，静态方法中不能调用非静态方法，非静态方法可以调用静态方法和访问静态成员。可也通过对象调用，也可以通过类调用。

### const
1. 声明一个常量
2. 指向变量的常量指针`int * const`与指向常量的指针`const int *`
3. 类中修饰函数，修饰的是this指针，该方法不能改变成员，但可以通过`mutable`使成员变量可以更改，不能调用非const函数
4. 修饰传入的引用或指针形参
5. 修饰返回的指针或引用，保护指针指向的内容或引用的内容不被修改

### short/long
![img](https://img-blog.csdn.net/20130913163641750?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvU2t5X3Fpbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)
只有`long`和指针的大小会因机器位数改变。

### memcpy/strcpy/strncpy

```c++
void* memcpy(void* s1, void*s2, size_t n);
char* strcpy(char* s1, const char* s2);
char* strncpy(char* s1, const char* s1, size_t n);//最多复制t个字符，到\0停止
```

## 刷盘
- libc库提供函数，平台无关，只有使用到c语言的标准文件操作时，才涉及到fflush。
- sync系列是系统提供用的系统调用，与平台相关。
### fflush
```c++
fflussh(FILE*);
```
把C语言FILE的缓冲区要写入文件的内容刷到操作系统的写入缓冲区，即内核缓冲区(页高速缓存)。

### sync
```c++
sync();
fsync(int fd);
fdatasync(int fd);
```
把内核缓冲区中要写入磁盘的数据刷新到磁盘上。

FILE缓冲---**fflush**--->内核缓冲----**fsync**--->磁盘

`sync`，只将页高速缓存中所有修改过的块的地址放入写入队列，然后返回，不等待实际写磁盘操作结束。

`fsync`，`fdatasync`只对fd指定的文件起作用，并且等到写磁盘结束才返回。
一般后两个用于数据程序，保证返回时即完成写入。

`fsync`不仅会将数据写入磁盘，还会将更改的文件属性也刷到磁盘的文件元数据inode部分。

`fdatasync`只影响文件的数据部分。

# 计算机网络
## 网络模型
### TCP
物理层、数据链路层、网络层、传输层、应用层

### OSI
物理层、数据链路层、网络层、传输层、会话层、表示层、应用层

物理层：为数据端设备提供原始比特流的传输通路。中继器、集线器、网线

数据链路层：将ip分组封装成mac帧。网桥，交换机。

网络层：为数据在结点之间传输创建逻辑链路，并分组转法数据。路由器、交换机、IP、ICMP。

传输层：提供应用进程之间的逻辑通信。TCP、UDP

### 为什么要分层
1. 各层之间相互独立，高层不需要知道底层功能是如何实现的，只需要调用底层的接口就可以。

2. 内部变化对外部不可见，不会对其他层产生影响。

3. 易于实现和标准化，将复杂的网络通信分解为一系列的功能模块。

## 数据链路层协议
### ARP/RARP
实现MAC地址和IP地址的转换。

#### ARP原理
主机向自己所在的网络广播一个ARP请求，该请求包含目标机器的网络地址，此网络上的所有机器都将接收到该请求，只有目标机器会相应一个ARP应答。

本地主机维护一个高速缓存，其中包含经常访问的服务器IP地址到物理地址的映射，从而避免了ARP请求的过程。

## 网络层协议
### IP
![](https://ss0.bdstatic.com/70cFuHSh_Q1YnxGkpoWK1HF6hhy/it/u=438227266,3332530122&fm=26&gp=0.jpg)

### ICMP
主要用于检测网络连接
报文格式
![](https://img-blog.csdn.net/201805301801365?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2JhaWR1XzM3OTY0MDcx/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

#### 差错报文
#### 查询报文

## 传输层协议
### TCP/UDP
1. TCP和UDP都是计算机网路中传输层的一种协议。
2. TCP是面向字节流的，将上层交付的数据包以字节流的形式发送，而UDP是基于数据报的。
3. TCP是面向连接的，在传输数据时需要在通信双方建立连接三次握手，断开连接三次挥手。而UDP是无连接的。
4. TCP可靠连接是因为TCP通过序号确认、重传机制来保证了数据无差错，不重复，不丢失，而UDP尽最大努力交付，不保证可靠。
5. TCP在传输过程中存在拥塞控制，而UDP不存在拥塞控制，虽然可能会有部分数据丢失，但其适用于对时延要求较高的某些场景，但在有些场景下也有可能会引起网络产生严重的拥塞问题。
6. TCP是一种点到点的通信只能一对一，而UDP支持一对多、多对多的方式。

### UDP
UDP有两个字段：数据字段和首部字段。
UDP最大报文段长度65535

#### 首部字段
首部字段只有八个字节。
1. 源端口
2. 目的端口
3. 长度，最小值为8，只有头部
4. 校验和(加入伪首部计算)

### TCP
1. TCP是一种面向连接的传输层协议，应用程序在使用TCP传输数据前必须建立连接，结束之后也要断开连接。
2. TCP传输是可靠的，保证分组无差错不丢失、不重复。主要是同学序号确认和重传机制来实现的。
3. TCP是一种全双工通信，因为设有接收和发送缓存，因此连接的两端可以在同一时刻发送数据或接收数据。
4. TCP是一种面向字节流的通信，对于应用层交付的数据分组，均看作一串无结构的字节流，可能会导致粘包问题。
5. TCP连接是点到点，只支持一对一的通信。

#### 首部字段
固定首部字段20个字节，可变长度为40字节，整个首部最长为60字节
1. 源端口/目的端口
2. 序号 4字节
3. 确认号 4字节
4. 数据偏移 4位
5. 保留字 6位
6. 标志位 6位
   紧急URG、确认ACK、推送PSH、复位RST、同步SYN，终止FIN
7. 窗口 2字节
8. 校验和 2字节
9. 紧急指针 2字节

#### TCP报文长度
TCP报文数据段长度最大MSS，默认为536字节，此长度不包含首部。


#### TCP三次握手、四次挥手
![三次握手](https://static001.geekbang.org/resource/image/65/29/65cef2c44480910871a0b66cac1d5529.png)
![四次挥手](https://static001.geekbang.org/resource/image/b8/ea/b8911347d23251b6b0ca07c6ec03a1ea.png)

#### 可靠传输
##### 停止等待协议
发送方发一个等一个确认，超时重传。

##### 连续ARQ协议
发送方接收到确认之后，向前移动窗口。
接收方累计确认，对按序到达的最后一个分组发送确认。缺点在于若丢失了中间一个分组，发送方会重发丢失分组之后的所有分组(GoBackN)。

##### 选择确认
为了解决累计确认中，对丢失分组后的数组的重复发送问题，提出SACK选择确认。

在TCP连接建立时，在首部加入允许SACK选项，在可变长度中记录不连续区域的上边界和下边界。每个边界需要4个字节，另需要一个字节指明是SACK，一个字节指明需要占用多少字节，最多只能指明四个字节块的边界信息，每个字节块两个边界，4*8+2=34

#### 滑动窗口实现流量控制
发送窗口不应超过接收窗口的大小，TCP窗口单位是字节。

1. Nagle算法
   若发送方应用进程要把发送的数据逐字节地送到TCP发送缓存，则发送方就将第一个数据字节先发送，将后面的字节缓存起来，当发送方接收到第一个字节的确认后，再将发送缓存的所有数据组装成一个报文段发送出去。同时对之后的数据进行缓存，即只有在接受到前一个报文段的确认后才发送下一个报文段。当待发送的数据已经达到发送窗口的一半或已经达到报文段的最大长度时，就立刻发送一个报文段。

#### 拥塞控制
流量控制是端对端的问题，只需要由接收端和发送端来决定，通过抑制发送端的发送速率是的接收端来得及接收。

拥塞控制是由网络拥塞程度决定的。

swnd = min[rwnd, cwnd]

基于窗口的拥塞孔，发送方维持一个拥塞窗口cwnd，大小取决于网络的拥塞程度。

只要发送方没有按时接收到应当到达的确认报文，即出现了超时，就认为网络出现了拥塞。

1. 慢开始
由小到大增大拥塞窗口，指数增长，慢并不是指增长速度慢，而是指初始拥塞窗口大小很小。需要设置一个慢开始门限ssthresh，当cwnd小于ssthresh时，使用慢开始，当cwnd大于ssthresh时，使用拥塞避免，相等时，无所谓。超时后，ssthresh设置位拥塞窗口的一半。

2. 拥塞避免
线性增长(加法增大)

3. 快重传
要求接收方不要等到自己发送数据时捎带确认，而是要立即发送确认，即使收到了失序的报文段也要立即发出对已收到报文段的重复确认。
例如在接收到报文段M1，M2，分别要发送其确认号，接下来收到了M4报文段，此时就要重复确认M2三次。

4. 快恢复
一旦发生快重传，发送方将门限值ssthresh设置为拥塞窗口的一半，拥塞窗口也设置一半，并执行拥塞避免算法。(乘法减小)


#### TCP粘包
发送方发出的若干数据包被接收方接收时按照一个数据包接收了。

产生原因：
1. 发送方，TCP有一个Nagle算法来处理小分组，为了保证不频繁地发送小分组，Nagle算法只有在上一个分组得到确认时，才会发送下一个分组，且会将多个小分组合并到一起一同发送。
2. 接收方收到分组之后，没有及时的进行处理，先将分组放到接收缓存中，当TCP接收分组的速度大于应用层读取速度时，就会在缓冲区中存在多个分组。

解决方法：
1. 在数据包头部加入数据包长度字段。
2. 在数据末尾增加分割符`\r\n`

## 应用层协议
### DNS
基于UDP，端口号53

![image-20200707142641994](C:\Users\May\AppData\Roaming\Typora\typora-user-images\image-20200707142641994.png)

- 根域名服务器
所有的根域名服务器都知道所有的顶级域名服务器的域名和IP地址。本地域名服务器若堆互联网上任何一个域名无法解析，首先求助于根域名服务器。
- 顶级域名服务器
负责管理在该顶级域名下注册的所有二级域名。
- 权限域名服务器
- 本地域名服务器

![image-20200707145744083](C:\Users\May\AppData\Roaming\Typora\typora-user-images\image-20200707145744083.png)

主机向本地域名服务器的查询是递归查询，本地域名向根域名服务器的查询通常是采用迭代查询。

### FTP
基于TCP实现文件传输，使用C/S架构，控制端口号21，数据端口号20，建立两个TCP连接，控制连接在会话期间一直保持打开。

FTP服务器进程采用Reactor模型。

### TFTP
简单文件传输协议，可以基于UDP。

### TELNET
远程终端协议，基于TCP连接远程主机，可以将用户的输入传到远程主机，C/S架构。

### HTTP
- URL
统一资源定位符，<协议>://<主机>:<端口>/<路径>

- URL
统一资源标识符

#### 基本概念

HTTP基于TCP协议，保证数据的可靠传输，端口号80。

HTTP协议本身是无连接，即同一个客户第二次访问同一个服务器上页面时，服务器响应与第一次访问时相同。

HTTP/1.0只支持短连接，每次发出http请求都会经历创建TCP连接、发送资源、断开TCP连接的过程。

HTTP/1.1引入长连接，`keep-alive`，保持TCP连接一定的时间。分为两种，一种是非流水线方式，一种是流水线方式，流水线方式可以在未收到响应报文时继续发送请求报文。

#### 报文结构
1. 请求报文
   1. 请求行
   2. 请求头
   3. 请求正文
   
2. 响应报文
   1. 状态行
   2. 响应头
   3. 响应正文

#### 请求方法
1. GET
请求读取指定url页面的信息，返回主体。

2. POST
向指定资源提交数据并处理请求。

3. HEAD
请求读取指定url页面的信息的头。

4. PUT
在指明的url种存储数据。

5. DELETE
删除URL的资源，指定页面。

6. OPTION
请求一些选项信息。

7. CONNECT
代理服务器

#### GET/POST
1. 都包含请求头、请求行，POST多了body，用以存储提交的数据
2. GET多用于查询，参数放在url中，POST用来提交，内容放在body中。
3. GET提交的信息可以在url中直接看到，而POST放在报文中，用户无法直接看到，POST也可以在url中传递参数。
4. GET提交的数据长度有限制，因为url长度有限制，而POST没有

#### 响应状态码
1. 1xx信息型
   - 100 Continue
      服务器通知浏览器一切正常，请客户端继续请求。
   - 101 Switching Protocal
   
2. 2xx成功型
   - 200 OK
      请求成功
   - 201 Created
      常用于POST，PUT请求，表明请求成功
   - 202 Accepted
      请求已经接收到，但没有响应。
   
3. 3xx重定向
   - 300 Multiple Choice
      返回多个响应，需要浏览器或用户选择
   - 301 Moved Permanently
      永久重定向
   - 302 Found
      临时跳转

4. 4xx客户端错误
   - 400 Bad Request
      请求语法有问题
   - 401 UnAuthorized
      未授权
   - 403 Forbidden
      权限不足，服务器拒绝响应
   - 404 Not Found
      指定url不存在

5. 5xx服务端错误
   - 500 Internal Server Error
      服务器内部错误，未捕获
   - 502 Bad Gateway
      服务器作为网关时，收到上游服务器返回的无效响应
   - 503 Service Unavailable
      服务器无法服务，一般过一段时间会恢复正常。
   - 505 Http Version Not Supported
      发出的请求http版本服务器不支持

#### 请求头参数
1. Host
2. Connection
3. User-Agent
4. Accept-Language

#### Cookie
前面所述HTTP是无状态的，使用Cookie来跟踪用户。

当用户A访问某网站时，网站服务器为用户产生一个身份识别码作为索引存储在服务器后端数据库中即Session_id。并在给A的HTTP响应报文中添加一个`Set-cooke`的响应行，用户在接收之后，将Cookie存储于本地，当用户A再次访问该网站时，就会将该Cooke放入HTTP请求报文中。

Cookie的结构中有生存期、Cookie值，服务器哪些页面可以使用Cookie。

客户端访问服务器时，服务器会通过一个`set-cookie`字段返回一个`cookie`值，客户端将其保存，并在每次访问该服务器时都携带该值，服务器在后续请求中，会检查`cookie`中的数据，抽取用户ID并对应到服务器端的用户会话对象。

`set-cookie`是可以多次使用的，每一个`key-value`都是一个独立的cookie，服务器会传送多个不同的cookie到客户端，每个cookie都有对应特定的业务目标。

#### Session
服务器端创建Session，用于跟踪用户，一般用Redis/Memcached存放。Session本身是一个抽象的概念。Session没有标准化的定义及实现方式，因此在不同编程语言中实现方式不同。

电商网站中的购物车数据究竟是保存在cookie中还是session中，若保存在session中，则会大幅度增加服务器的存储压力，为了缓解服务器的压力，我们应当尽可能少放大尺寸的数据在session中，并尽早清除无效数据释放session占用的内存。若将数据转移到cookie中，由于每次客户端发出的的http请求都会发送cookie，增加了网络传输的压力。

#### 分布式Session
将Seesion数据单独保存在外部内存中间件(缓存)中，如Redis、Memcache、JBossCache。

#### Token
由于cookie是存放于磁盘上，并且cookie中含有sessionid，且cookie中的信息是明文保存的，因此攻击者可以伪造cookie数据破解系统。避免这种攻击的方法就是用数字证书对敏感数据进行加密签名，加密后的字符串就是所谓的Token，这样攻击者就没有办法伪造Token了，Token的本质是Session的改进版，Token将用户状态信息保存在了Token字符串里，服务器端不再维护客户端状态，Token数据被放在HTTP Header`X-Auth-Token`中保存，但客户端拿到Token之后可以将其保存在手机中。

Token与Cookie完全无关。

#### HTTP缺点
1. 请求信息明文传输，不能保证机密性
2. 数据完整性未校验，易篡改
3. 服务端没有验证身份，易冒充

#### HTTP版本

##### HTTP1.0

##### HTTP1.1

1. 增加了缓存处理字段
2. Host头处理
3. 长连接，流水线

##### HTTP2.0

1. 同时支持http和https
2. 消息头压缩
3. 多路复用，每一个request对应一个id，一个连接上有多个request，可以混杂在一起，接收方可以根据id将request归属到不同的服务端请求里

##### HTTP3.0
谷歌的QUIC协议从TCP切换到UDP。



### HTTPS
端口号443
HTTP over Secure Socket Layer

HTTP + SSL/TSL

TSL(Transport Layer Security) 传输层安全，前身SSL，目前广泛使用TSL1.1和TSL1.2

#### HTTPS过程
![HTTPS](https://img2018.cnblogs.com/blog/1223518/201908/1223518-20190818111014781-1699339583.png)

1. TCP三次握手建立TCP连接
2. 客户端发送Client Hello，并携带所支持的TSL版本、可供选择的加密算法列表、随机数a，服务端ACK确认
3. 服务端Server Hello，确定TSL版本、加密算法、随机数b
4. 服务端发送证书、公钥、ServerHello
5. 客户端验证服务端身份，生成对称加密的随机密钥
6. 客户端将随机密钥用服务端公钥进行加密发送。
7. 服务端返回加密后的密钥。

客户端首先向服务端发送请求，并且附带自己支持的加密协议版本等信息，服务端根据客户端的请求选择合适的加密协议，并将自己得证书返回，证书包括公钥和数字签名。客户端首先进行验证，验证成功后

#### HTTPS缺点
1. 多次握手，页面加载时间长
2. 连接缓存不如HTTP高效，有额外的数据开销
3. SSL证书昂贵
4. SSL涉及安全算法，占用CPU资源，对服务器资源消耗较大

#### 客户端验证公钥证书
服务端将公钥和数字签名发送给客户端，客户端通过数字签名来判断该公钥的合法性(是否是真实的目的方)，需要第三方认证机构的认证，第三方认证机构会将服务端的公钥用第三方的私钥进行加密得到数字签名，客户端只需利用第三方认证机构的公钥对数字签名进行解密，是否与服务端公钥一致即可，这里的前提是第三方应当是可信的。


### SMTP
简单邮件传输协议，端口号25，基于TCP

### POP3/IMAP
邮局协议3/网际报文存取协议


# 并发
## 无锁队列
```c++
struct queue{
   int head;
   int tail;
   int size;
   int* data;
   queue():size(10){
      data = new int[size];
   }
   queue(int _size):size(_size){
      data = new int[size];
   }
   bool isEmpty(){
      if(tail == head)
         return true;
      return false;
   }
   bool isFull(){
      if(tail+1 % size == head)
         return true;
      return false;
   }
   int write(int num){
      if(!isFull()){
         data[head] = num;
         ++head;
         return 1;
      }
      return -1;
   }
   int read(){
      int num;
      if(isEmpty()){
         num = data[tail];
         tail++;
         return num;
      }
      return -1;
   }
};


```

# 网络编程
## HTTP服务器
### 主从reactor模式
主从reactor主要是实现了连接建立事件和已建立连接的IO事件分离。主线程只负责分发Acceptro连接建立，已建立套接字上的IO事件交给sub-reactor负责分发。
### TCP高性能框架
首先创建一个eventloop对象作为主reactor，创建一个acceptor对象(处于监听状态)，然后创建tcpServer对象，并将前面的eventloop和acceptor对象以及对应的回调函数赋给该tcpserver对象，该tcpServer对象包含一个线程池作为从reactor对象。

tcpServer启动，启动线程池中的多个线程，每个线程创建一个eventLoop并启动。当有事件发生时，判断所有就绪事件的类型，并通知eventLoop执行其对应的回调函数，channel_map实现了文件描述字到channel事件的映射，从而可以确定其回调函数。

为acceptor的监听事件创建一个channel，回调函数为处理连接请求，注册到主eventLoop上。

主反应堆启动后，阻塞于epoll_wait，当监听到新的连接请求，就执行回调函数创建一个accept套接字，然后从线程池中取一个线程，建立一个新的tcp连接，为该线程所属的eventLoop注册回调函数(读写)。

读写操作都通过buffer来完成，若回调为写事件，则直接从out_buffer中，向套接字发送数据。若回调为读事件，则直接从inbuffer中读取数据

## select/poll/epoll
1. 三者都属于I/O多路复用技术
2. 阻塞I/O，对于已经建立连接的套接字，我们调用`read`去读数据，如果这是内核缓冲区中没有接收到数据，那么`read`就会一直阻塞在这里，知道内核缓冲区接收到数据之后，函数才会返回。这期间进程/线程处于阻塞状态做不了其他事，如果是单进程/线程，这时候如果其他事件发生，也没有办法去处理，如果是多线程，对于高并发场景，需要为每个I/O事件分配一个线程/进程去处理，同样会阻塞，进程/线程做不了其他任何事，而操作系统中线程和进程需要占用资源，因此是不合适的。
3. 非阻塞I/O，若内核缓冲区中没有接收到数据，`read`就会返回-1，我们就可以通过循环的方式不停地去检查事件是否准备好，也就可以在同一个线程或/进程中去处理多个I/O事件。但一直轮询是要占用cpu的，所以即使没有事件的发生，也会占用cpu资源，所以说单独的非阻塞I/O其实本身也是低效的。
4. 为了适应高并发场景，I/O多路复用的思想就是，维护一个多个事件的列表，如果有事件发生，才通知程序去处理，I/O多路复用本身也是阻塞的，select/poll/epoll是三种不同的I/O多路复用方法。
5. select的事件集合是通过一个fd_set的数据结构来实现的，fd_set其实是用位来存储每个事件，因为fd_set是已经定义好的，所以select最多只能处理1024个事件，修改起来很麻烦，需要去重新编译内核。
select调用本身是阻塞的，调用时，首先将事件集合拷贝到内核去，当有事件发生时，select调用返回，然后在程序中遍历调用返回的状态来判断是哪个事件发生了。select会直接修改传入的事件集合，所以需要保存事件集合，每次循环都要为传入select的事件集合重新赋值。分三种(read, write, except)事件。

select一般大家都说他需要轮询，我理解的轮询有两种，一种是在内核区，一种是select返回后需要对返回的事件集合进行遍历。在内核区，可能存在两次获多次遍历，第一次遍历调用poll

select源码：调用时，首先需要将整个的事件集合从用户去拷贝到内核区(`get_fd_set`)，然后将内核状态全部置0(`zero_fd_set`)，调用`do_select()`阻塞，事件发生时返回，然后将事件状态集合拷贝到用户区(`set_fd_set`)。调用`do_select()`过程中，会对所有的文件描述符进行遍历，调用`poll`为每个文件描述符申请一个等待队列元素，然后将其添加到对应驱动的等待队列中，然后进行睡眠。poll调度返回两种情况，一种是超时，一种是中断发生，若有中断发生，则将timeout置1，然后重新遍历，根据mask值来将对应的文件描述符状态置1，表示该事件发生。

6. poll的行为和select是类似的，底层都是通过poll实现的，在源码里也能看到很多poll、select共用的函数，区别在于poll是用一个`pollfd`数组来传入事件集合，我们可以自己声明数组的个数，实现是用了`poll_list`链表来存储的，因此没有最大连接数的限制。

poll调用的原理，先注册回调函数`__poll_wait`，然后初始化table(`poll_wqueues`)，拷贝用户传入的pollfd数组，轮询文件描述字，为其申请一个等待队列元素，将其添加到对应驱动的等待队列中，然后进行睡眠。当有中断发生时，唤醒进程/线程。

7. epoll首先是接口上的改进，`select`和`poll`的接口只有一个，在循环里面调用`select`和`poll`，每次都会从用户区到内核区的完成描述字的拷贝，而epoll将接口分为了三个`epoll_create,epoll_ctl,epoll_wait`，`epoll_create`创建一个epoll的对象，然后`epoll_ctl`向内核区注册事件，完成从用户区到内核区的拷贝，在循环里面只需要调用`epoll_wait`阻塞等待事件的返回即可，不需要每次都拷贝。

8. epoll_wait不像select和poll将所有的事件都返回，而是只返回准备就绪的事件集合。这样在epoll_wait返回后就不需要遍历整个事件集合来找到判断哪些事件发生了，当事件集合很大时，而活跃事件又很少，可以极大地提高效率。

9. 并且epoll实现上，对于事件的触发定义了两种方式，水平触发和边缘触发，水平触发的意思是，以读数据为例，没有数据的时候标志位0，内核缓冲区中有数据标志为1，每次调用`epoll_wait`时，只要还有数据可读，就会返回它的事件，而在边缘触发中，只有每次内核区接收到数据时才会触发一次事件，如果一次没读完，也不会再返回该事件，只有在下一次接收到数据时，才会返回。因此我们在边缘触发的时候，要注意每次事件读触发时，我们每次都要将内核缓冲区读空再结束。如果有大量不需要读写的就绪文件描述符，不去读写，那每次调用都会返回该文件描述符，大大降低效率。

10. epoll中，当有事件发生时，便会执行回调函数，寻找对应的epollitem以及对应的eventepoll实例，并对事件进行过滤，epoll_insert注册时注册的是所有事件，过滤只返回用户需要的事件。
```c++
// 伪代码，省略一些参数
//SYSCALL_DEFINE5
int select(nfds, readfds, writefds, exceptfds, timeout){
   copy_from_user(timeout);
   set_time_out();
   ret = core_sys_select();
   ret = copy_remaining(timeout, ret); // copyt_to_user()
   return ret
}
int core_sys_select(nfds, readfds, writefds, exceptfds, timeout){
   // 相当于用户区到内核区的拷贝
   ret = get_fd_set(n, readfds, fds.in);   get_fd_set(n, writefds, fds.out);   get_fd_set(n, exceptfds, fds.ex);
   // 置0
   zero_fd_set(n, fds.x);
   ret = do_select(n, &fds); //阻塞，满足条件时返回
   // 内核区到用户区拷贝
   set_fd_set(n, readfds, fds.in); ...
   return ret;
}
int do_select(nfd, fds){
   timeout = 0;
   retval = 0;
   for(;;){
      for(int i=0; i<nfd; ++rinp, ++routp, ++rexp){
         mask = (*f_op->poll)(file, wait);
         if(mask&POLLIN_SET && (in&bit)){
            res_in |= bit;
            retval++;
         }
         if(mask&POLLIN_SET && (in&bit)){
            res_out |= bit;
            retval++;
         }
         if(mask&POLLIN_SET && (in&bit)){
            res_ex |= bit;
            retval++;
         }
      }
      if(retval || timeout)
         break;
      // 调度进入睡眠，若发生了终端则将timeout=1，若超时，则进行下一次循环
      if(!poll_schedule_timeout())
         timeout = 1;
   }
   return retval;
}
```

## 原始套接字/TCP/UDP套接字
TCP/UDP类型的套接字只能够访问传输层及以上的数据，当ip层交付给传输层时，已经将下层的包头丢掉了，而原始套接字却可以访问传输层以下的数据，直接获取数据链路层的数据包。非面向连接。

如果调用bind和connect，则原始套接字只接收指定ip和端口的数据包，若没有，则接收所有协议匹配的数据包。

## 本地套接字
本地套接字bind的不是一个网络地址，而是一个文件的绝对路径名，不像网络套接字那样需要经过协议栈，也不需要打包拆包，不需要计算校验和，只是将应用层数据从一个进程拷贝另一个进程。

`socketpair`可以创建一对无名的本地套接字，像管道一样使用。

# 操作系统
## 用户态/内核态
### 
### 系统调用
1. 应用程序调用库函数(API)
2. API将系统调用号存储到eax, 然后通过int 0x80号中断使系统陷入内核态
3. 内核中的中断处理函数sys_call根据eax中的系统调用号调用相应的系统调用
4. 系统调用完成相应功能，将返回值存入eax，返回到中断处理函数
5. 中断处理函数返回到API中
6. API将eax返回给应用程序

## 多级缓存一致性
缓存一致性协议MESI，用于保证多个CPUcache之间缓存共享数据的一致性。

E(Exclusive)：独享状态，该缓存行只被缓存在该CPU的缓存中，且是未被修改过的，与主存中的数据一致，该状态可以在任何时刻当有其他CPU读取该内存时变成共享状态，当CPU修改时，进入M状态。

M(Modified)：被修改(脏页)，该换缓存只存放在该CPU的缓存中，且是被修改过的，与主存不一致，所以该缓存需要在未来地某个时间被写回主存，写回之后，会进入E状态。

S(Shared)：共享状态。该状态意味着缓存行可能被多个CPU缓存，各个缓存中的数据与主存数据一致，当有一个CPU修改该缓存行时，其他CPU对该缓存行的缓存可以作废，进入无效状态。

I(Invalid)：该缓存是无效的。

### CPU读写时
读请求：若缓存处于M、E、S状态都可以读取，I状态只能从主存中读取。
写请求：缓存处于E、M状态才可以被写入，对S状态地写入，需要先将其他CPU中的缓存设置为无效才可以写入。

## 进程调度算法
1. 先来先服务FCFS
   属于不可剥夺算法，对于长作业有利，对于短作业不利，有利于CPU繁忙型作业，不利于IO繁忙型作业。

2. 时间片轮转法
   时间片的大小对系统性能影响很大，若时间片足够大，退化为先来先服务，若时间片很小，那么处理机在进程之间频繁切换，使处理机开销增大。

3. 短作业优先
   选最短的作业，不存在抢占机制，一旦开始执行就要执行完。不能保证作业紧迫性。对长作业不利，没有考虑作业的紧迫度，且作业时间长短是由用户所提供的估计执行时间决定的，不一定能真正做到短作业优先。

4. 最短剩余时间优先
   抢占式，只要等待队列中出现剩余时间最短的，可以抢占当前进程。长作业饥饿。

5. 高响应比有优先
   响应比$R = (W+S)/S$，其中，W为等待时间，S为预计的执行时间。

6. 优先级调度算法
   优先级用于描述作业运行的紧迫程度，在作业调度中，每次从后备作业队列中选择优先级最高的一个或几个作业，将其调入内存，分配资源创建进程并放入就绪队列中。在进程调度中，每次从就绪队列选择优先级最高的进程，为其分配处理机。根据高优先级是否能抢占当前进程分为：剥夺式优先级调度算法和非剥夺式优先级调度算法。

7. 多级反馈队列调度算法
   1. 设置多个就绪队列，并未每个队列赋予不同的优先级，第一级队列优先级最高。
   2. 赋予每个队列进程执行时间片的大小各不相同，优先级越高的队列中，时间片越小。
   3. 若当前队列的进程时间片结束时进程未完成，则将该进程转入下一优先级队列末尾，最底层队列采用时间片轮转法。
   4. 仅当高优先级队列为空时，才调度低优先级队列。

## PV操作
用PV操作来对信号量S进行操作，从而实现对共享资源的管理。
1. P操作
   1. S减一
   2. 若此时S大于等于零，则进程继续执行
   3. 若此时S小于零，则进程被阻塞进入等待该信号量的等待队列，进程调度
2. V操作
   1. S加一
   2. 若此时S大于0，则进程继续执行
   3. 若此时S小于等于0，则从该信号的等待队列中释放一个等待进程，返回原进程继续执行，或进行进程调度

## 进程/线程
### 进程 线程、协程
1. 进程是程序在操作系统中执行的实例，是操作系统进行资源分配和调度的基本单位，操作系统会为每个进程分配虚拟地址空间，32位机器上为4GB，地址空间分为内核区和用户区两部分，自高地址到低地址的第一个G为内核区，用户区依次为栈、堆、BSS段(未初始化的全局变量)、数据段(初始化的全局变量和静态变量)、字符串常量区、代码区。进程之间地址空间是相互独立的。
2. 线程是操作系统程序执行的最小单位，一个进程可以拥有多个线程，即使没有显式创建一个线程，也会为进程分配一个主线程，同一个进程里的多个线程共用进程的内存空间(代码区、全局变量、堆)，但线程拥有自己的线程栈、程序计数器等，因为共享进程的内空间，所以线程之间的切换代价远远小于进程切换，进程和线程的切换都涉及用户态和内核态的转换。一个进程所拥有的线程数目由线程栈的大小和进程的用户区大小决定。
3. 协程是比线程更加轻量级的，一个线程可以拥有多个协程，协程完全由程序控制，只在用户态执行，协程切换不涉及用户态和内核态的转换，协程切换时机是由程序决定的而不是操作系统。本质上协程是一种特殊的函数，可以在某个地方挂起、恢复执行，线程中的协程只能串行执行。

4. 线程栈是在进程得堆空间分配的，线程共享进程的地址空间、全局变量、代码区、打开的文件描述符、进程的当前目录、信号等，线程拥有自己的线程栈、寄存器、程序计数器等。

### 线程栈/进程栈
1. 线程栈在Linux下默认大小为8M，线程栈位于进程的堆区。
2. 进程栈是进程地址空间用户区的顶部。

### 进程状态
创建、就绪、执行、阻塞、终止

### 进程通信
#### 无名管道PIPE
只能用于父子进程通信，属于半双工通信，同一时刻只能存在单向的数据传输，通常是由父进程创建一个pipe，然后fork出的子进程同样有一个pipe句柄。是一种特殊的文件，只存在于内存中，不存在于文件系统。

#### 有名管道FIFO
能用于任意进程之间的通信，是存在于文件系统的一种文件，可以通过`mkfifo\mknod`方法创建，前者可以指明权限，后者需要用`chmod`重新指定权限。

#### 信号
只能传递有限的信息。

#### 消息队列
虽然叫做队列，但实际的数据结构是一个消息链表，由特定的格式和优先级，可以按类型进行读取。

#### 信号量
用于实现进程之间的互斥和同步，原子操作。

#### 共享内存
通常和信号量一起使用。共享内存是进程间通信最快的方式。

同一块物理内存被映射至A、B各自的进程地址空间。

#### Socket
一种是本地Socket，一种是正常的


### 线程通信
1. 全局变量(临界区)
互斥量+条件变量来实现线程的互斥和同步
2. Message消息机制
`PostMessage`：异步，线程只能向主窗口发送消息
`SendMessage`：同步
`PostThreadMessage`：任意两个线程间通信
3. MFC中事件

## lock_guard/unique_guard
1. 二者都是mutex RAII的实现。
2. lock_guard只有构造函数，没有其他成员函数。
3. unique_lock提供了更多的成员函数，如`lock/unlock/try_lock/try_lock_for/try_lock_until`等。
4. RAII是为了解决`mtx.lock/unlock`中的问题，一旦在二者之间发生异常，便不能正常释放锁的问题，RAII下，一旦其生命周期结束，就会自动释放锁，但对于mutex对象是不负责的。

## 锁
1. 互斥锁

2. 读写锁
读写锁分为读锁和写锁，也就是共享锁和排他锁。

3. 自旋锁
互斥锁和读写锁在未获取到锁时，线程都会进入一个睡眠状态暂时放弃CPU，而自旋锁会不停地测试是否能获得锁，占用CPU。

自旋锁的主要应用是当等待时间很短，线程切换性能损耗占比较大时，才有自旋锁。例如多喝处理器中，线程等待锁的时间很短，短到比进行两次上下文切换的时间还要少，就可以使用自旋锁。单核处理器不建议使用自旋锁，因为同一时刻只有一个线程在运行，如果运行线程发现无法获取锁，这时候不放弃CPU进行自旋，而获得锁的线程就没有办法获得CPU，只能等待运行线程用尽操作系统分配给他的时间片，才可以被调度。

## 死锁
### 四个必要条件
1. 互斥
2. 请求和保持
3. 循环等待
4. 不可剥夺
### 预防死锁
1. 破坏请求和保持条件
   1. 一次性分配所有的资源
   2. 申请新资源时，释放旧资源
2. 破坏不可剥夺
   1. 若申请资源被拒绝，则放弃所占有的资源
   2. 设置进程优先级
3. 破坏环路等待
   - 为资源编号，申请资源按编号顺序提出。
### 避免死锁
允许进程动态地分配资源，但分配资源前，需要判断进行此次资源分配的安全性，即对分配后的状态的安全性进行判断。若安全则可以分配，若不安全则不分配。

银行家算法维护三个结构，总资源、已分配的资源、剩余可用资源，每次分配资源前，都要先判断分配后的状态是否安全，首先判断进程需求矩阵中是否存在一行小于剩余可用资源，若不存在，则系统将会发生死锁，状态是不安全的。若存在，则将该进程标记为终止，返还所有资源，重复上述步骤，若最终所有进程都可以完成，则这个状态是安全的。

### 检测死锁
当检测到死锁发生时，进行恢复，死锁检测算法是通过检测有向图是否存在环来实现的，若找到了环，则检测到了死锁。
### 死锁恢复
1. 资源剥夺法
2. 进程回退法
3. 进程撤销法

## 页面置换算法

1. OPT
   最佳置换算法，从主存中移除永远不需要访问的页面。理论。

2. FIFO
   利用队列实现先进先出，但是会存在Belady现象，当缓存增大时，缺页率反而上升，其原因是对于相同页访问序列，FIFO的小缓存并非大缓存的子集，因此会产生小缓存不缺页而大缓存缺页的现象。

3. LFU
   最近最少使用算法，记录访问页面在缓存中访问的次数，每次缺页时替换访问次数最小的页面。哈希表+小顶堆实现。

4. LRU
   最近最久未使用，若一个数据在最近一段时间没有被访问，则将来它被访问的可能性很小，当空间满时，最久没被访问的而数据被置换。哈希表+双向链表实现。

5. CLOCK(NRU)
   试图用比较小的开销接近LRU的性能，循环缓冲区，当某个页面首次加入主存时，将其使用位置1，若再被访问到，则同样将其置1。当某个页面被替换时，将指针指向缓冲区的下一帧，当需要页面替换时，指针遍历找到第一个使用位为0的帧，并将沿途经过的所有使用位为1的帧置0。


## 磁盘调度算法
### FCFS先来先服务
按照访问磁盘的先后次序进行调度，公平简单，不会产生饥饿现象。

缺点在于，没有对寻道进行优化，磁盘访问请求较多时，会降低设备的吞吐量，致使平均寻道时间增大。

### SSTF最短时间优先
要求访问的磁道与当前磁头所在的磁道距离最近，以使每次的寻道时间最短，会产生饥饿现象。

### 扫描算法
从里向外，再从外到里。

### 循环扫描算法
从里向外，到达最外部，立即返回最里面的磁道。


## 僵尸进程/孤儿进程
### 僵尸进程
父进程没有等待子进程结束，也没有为子进程注册相应的进程结束后的处理操作。

kill命令是不能消灭僵尸进程的，只能通过将父进程杀死，或者在创建时通过两次fork来使得孙子进程成为孤儿进程来避免。

### 孤儿进程
父进程先于子进程结束，那么子进程就会变为孤儿进程，被init1进程接管。

# 概念开放题
## 抢红包
微信红包是在拆的时候算出来的，而不是预先分配的，纯内存计算。

抢红包分为三个步骤，抢，拆，转账。第一步抢的时候，只判断红包是否有剩余，第二步拆的时候再计算金额。

Redis首先存储红包个数、金额和类型，app发起抢红包，先判断是否有剩余，如果没有，直接返回红包没了。紧接着app发起拆红包，会将一个红包请求加入到请求队列上，如果超过红包的个数，直接返回。（或者直接计数，没到来一个请求CAS减一）

## C++/Python/Java
1. C++属于编译型语言，需要将源代码先编译成目标语言，然后通过链接程序连接生成的目标文件。
2. Python属于解释性语言，由解释器根据输入数据直接执行而不生成任何目标程序。不需要类型声明，语法简单，编程效率高。
3. Java属于混合型语言，也需要编译，但没有直接编译成机器码，而是编译为字节码，然后在JVM上用解释方式执行字节码。

## 从浏览器输入URL发生了什么
1. 在浏览器中输入url地址
2. 解析URL得到host和请求，判断是否具有该http请求的强缓存，如果有直接返回，如果没有则继续
3. 根据host执行相应的DNS解析过程
    1. 查询本机缓存，若有返回，若没有查询本机hosts是否有对应ip，若有则返回，若无则继续
    2. 若没有找到对应hosts，浏览器会发出一个dns请求到本地dns服务器(配置ip时配置的)
    3. 本地dns服务器首先查询缓存记录，若有则返回，若无继续
    4. 本地dns向根域名服务器查询
    5. 根域名服务器告知本地dns服务器该url的顶级域名服务器地址，本地dns去向顶级域名服务器发出请求
    6. 顶级域名服务器查询缓存若有则返回，若无则告知本地dns服务器该url得下一级域名服务器地址，本地dns去查询，返回ip地址，并缓存。
    
5. 建立TCP连接，以随机端口(1024~65535)向服务器80端口建立TCP连接请求，三次握手
6. 发起HTTP请求
7. 服务端处理，返回数据
8. 关闭TCP连接
9. 浏览器解析数据
10. 浏览器渲染布局

## traceroute
traceroute利用ICMP协议定位计算机与目的计算机之间的所有路由，TTL可以反应数据包经过的路由器或网关数量。

原理：TTL为0时，会返回目的地不可达报文，因此设置TTL从1开始递增，就可以获得路径信息，但不保证每个数据包经过相同的路径。

# Linux
## Linux常用信号
- `SIGHUP`: 用户终端连接结束时发出，默认终止进程。
- `SIGINT`: 程序终止(Interrupt)信号，在键入`Ctrl-C`时发出，通知前台进程终止。
- `SIGQUIT`: `Ctrl+\`发出，类似于SIGINT，进程退出时会产生core文件，类似于一个程序错误信号。
- `SIGTRAP`: 断点产生。
- `SIGSEGV`: 试图访问未分配给自己的内存，或试图向没有写权限的内存地址写数据。
- `SIGIO`: 文件描述符就绪。
- `SIGSYS`: 非法系统调用。
## glibc
是Linux系统中最底层的api，封装了Linux操作系统提供的系统服务，几乎任何运行库都会依赖于glibc

## Linux创建进程
1. fork()
   不带参数，将父进程的所有资源进行复制。

2. clone()
   有参数，可以指定资源进行复制。

3. exec()


# 汇编
## 寻址
1. 立即寻址，指令中直接提供源操作数。
2. 直接寻址，给出操作数的地址。
3. 寄存器寻址，操作数存放于寄存器中。
4. 寄存器间接寻址，寄存器中给出存储单元的地址。
# 算法
## 最短路径算法
### Dijkstra    O(n^2)
单源最短路径算法，每次找到离源点最近的一个顶点，然后以该顶点为中心进行扩展，最终得到源点到所有点的最短路径。

### 弗洛伊德算法   O(n^3)  空间O(n^2)
多源最短路径，最开始只允许经过1号顶点进行中转，然后允许经过1号和2号定点进行中转，不断更新任意两点之间的最短路程，即求从i号顶点到j号顶点只经过前k号顶点的最短路程。

### 布尔曼福特算法  O(nm) O(m)
单源最短路径，前几种方法都不能求含负权边的图。
n为顶点数，m为边数。

## 布隆过滤器
布隆过滤器主要可以用来告知某个关键字一定不存在或可能存在。相比于hash，其占用空间更少，且高效，但其返回的结果时概率性的。通过多个不同的hash函数，将某个关键字映射到一个bit向量/数组中，当我们查询时，若某个关键字所对应的所有hash结果，在bit数组中有一个为0，则该关键字一定不存在，若均为1，则可能存在。
若布隆过滤器大小过小，那么很快就会导致所有bit位均为1，则查询任何值均会返回可能存在。hash函数越多，则布隆过滤器bit位置1的速度越快，且布隆过滤器的效率越低，若hash函数太少，假设为1，则只要一个不为0，就会认为其可能存在，导致误报率变高。而若存在多个hash函数，则有任意一个为0就说明一定不存在。

应用场景，使用布隆过滤器减少磁盘IO或网络请求。

## 红黑树
### 八大排序
![](https://img2018.cnblogs.com/blog/1037310/201903/1037310-20190303223301706-1091682598.png)


### 红黑树出现的原因
AVL树对于平衡性要求太高，导致每次插入删除操作都会引起AVL树的旋转调整。
### 红黑树定义
1. 所有的节点是红色或黑色
2. 根节点为黑色
3. 所有的叶子节点均为空且(或者说所有的空节点)为黑色
4. 不能有父子节点同为红色
5. 从任意节点出发到叶结点的所有路径，所经过的黑色节点数相同

### 红黑树理解
红黑树是一种黑色完美平衡二叉树，最差情况是某一棵子树是红黑完全相间，查找复杂度(2logn)，平均查找复杂度为(logn)。

### 红黑树的插入
新插入节点必须为红色。
1. 若父亲节点为黑，则不需要进行任何操作
2. 若父亲节点为红，且叔叔节点为红，则将父亲节点和叔叔节点置为黑，然后将祖父节点置为红。此时若曾祖父节点为黑则结束，若曾祖父节点为红，则继续进行调整。
3. 若父亲节点为红，且叔叔节点为黑(或不存在)，则进行旋转，旋转规则与AVL树相同，当调整为左左/右右进行下一步旋转时，需要将祖父节点置为红，两个叶节点置为黑。(原本应当是祖父节点为黑，单向边的叶子节点和父亲节点均为黑)

### 红黑树的删除
1. 若被删节点无子节点且为红，则直接将节点删除。
2. 若被删节点无子节点且为黑，分四种情况(我死了)
3. 若被删节点有一个子结点，且被删节点为黑(不可能为红，违反定义5)，则用该红色子节点(不可能为黑，违反定义5)替代该节点，并将节点置黑
4. 若被删节点有两个子节点，找到中序遍历中该节点的下一个节点，用其替代该节点并将其置为被删节点的颜色。此时相当于该后继节点被删，对应上述某一删除原则。

## sort
插入排序、堆排序、快速排序。
c++中的sort，首先是快排的改进，利用三值(start, mid, end)三者得中间值作为枢纽来进行快速排序，当分割行为仍然有恶化为二次方的倾向时(递归深度恶化，即递归深度达到限制时)，就会转而调用堆排序。
当元素数量小于16时，直接采用插入排序。

## rand5生成rand7
rand5()能生成1到5

首先证明，rand7可以实现rand5
$$
p(x=1) = 1/7 + (2/7)*(1/7) + (2/7)^2 * (1/7) + \dots \\
= (1/7)*(1+ (2/7) + (2/7)^2 + \dots)//等比数列 \\
= (1/7) * (1/(1-(2/7)))\\
= 1/5
$$
那么我们只要能通过rand5生成一个大于7的随机数生成器即可。
$$
rand25() = 5*(rand5()-1) + rand5()
$$
```python
def rand7():
   res = 25
   while(res>21):
      res = 5 * (rand5() - 1) + rand5()
   return res%7+1
```

## 输入一个正整数，求和等于这个正整数的全部正整数连续序列

## 蓄水池采样
给定数据流，内存存不下，在O(N)时间内，随机选取m个数据
```c++
vector<int> num(m);
for(int i=0; i<m; i++)
   num[i] = dataStream[i];
for(int i=m; i<dataStream.size(); ++i){
   int d = rand.nextInt(i+1);
   if(d < m)
      num[d] = dataStream[i];
}
```
对于第i个数据，生成一个[0,i]之间的随机数d，若在$[0，m)$之间，则替换num[d];
### 分布式蓄水池采样
将数据流分为k个数据流，每台机器采用蓄水池采样选取m个数据，并记录不同数据流的长度N1,N2...

在[1,N]中选取一个随机数d，若$d<N_1$则在第一台机器上不放回选取一个数据，若$Ni-1<d<Ni$则在第i台机器上不放回选取，重复m词。